{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Understanding of Convolutional Neural \n",
      "Network (CNN) — Deep Learning  \n",
      "In neural networks, Convolutional neural network (ConvNets  or \n",
      "CNNs) is one of the main categories to do images recognition, \n",
      "images classifications. Objects detections, recognition faces etc., are \n",
      "some of the areas where CNNs are widely used.  \n",
      "CNN image classifications takes an input image, process it and \n",
      "classify it under certain categories (Eg., Dog, Cat, Tiger, Lion). \n",
      "Computers sees an input image as array of pixels and it depends on \n",
      "the image resolution. Based on the image resolution, it will see h x w \n",
      "x d( h = Height, w = Width, d = Dimension ). Eg., An image o f 6 x 6 \n",
      "x 3 array of matrix of RGB (3 refers to RGB values) and an image of \n",
      "4 x 4 x 1 array of matrix of grayscale image.  \n",
      " \n",
      "Figure 1 : Array of RGB Matrix  \n",
      "Technically, deep learning CNN models to train and test, each input \n",
      "image will pass it through a seri es of convolution layers with filters \n",
      "(Kernals), Pooling, fully connected layers (FC) and apply Softmax \n",
      "function to classify an object with probabilistic values between 0 and \n",
      "1. The below figure is a complete flow of CNN to process an input \n",
      "image and class ifies the objects based on values.  \n",
      " \n",
      "Figure 2 : Neural network with many convolutional layers  \n",
      "Convolution Layer  \n",
      "Convolution is the first layer to extract features from an input image. \n",
      "Convolution preserves the relationship between pixels by learning \n",
      "image features using small squares of input data. It is a \n",
      "mathematical operation that takes two inputs such as image matrix \n",
      "and a filter or kernel.  \n",
      " \n",
      "Figure 3: Image matrix multiplies kernel or filter matrix  \n",
      "Consider a 5 x 5 whose image pixel values are 0, 1 and  filter matrix 3 \n",
      "x 3 as shown in below  \n",
      " \n",
      "Figure 4: Image matrix multiplies kernel or filter matrix  \n",
      "Then the convolution of 5 x 5 image matrix multiplies with 3 x 3 \n",
      "filter matrix which is called  “Feature Map”  as output shown in \n",
      "below  \n",
      " \n",
      "Figure 5: 3 x 3 Outpu t matrix  \n",
      "Convolution of an image with different filters can perform \n",
      "operations such as edge detection, blur and sharpen by applying \n",
      "filters. The below example shows various convolution image after \n",
      "applying different types of filters (Kernels).  \n",
      " \n",
      "Figure 7 :  Some common filters  \n",
      "Strides  \n",
      "Stride is the number of pixels shifts over the input matrix.  When the \n",
      "stride is 1 then we move the filters to 1 pixel at a time. When the \n",
      "stride is 2 then we move the filters to 2 pixels at a time and so on. \n",
      "The below figure shows convolution would work with a stride of 2.  \n",
      " \n",
      "Figure 6 : Stride of 2 pixels  \n",
      "Padding  \n",
      "Sometimes filter does not fit perfectly fit the input image. We have \n",
      "two options:  \n",
      " Pad the picture with zeros (zero -padding) so that it fits  \n",
      " Drop the part of the image where the filter did not fit. This \n",
      "is called valid padding which keeps only valid part of the \n",
      "image.  \n",
      "Non Linearity (ReLU)  \n",
      "ReLU stands for Rectified Linear Unit for a non -linear operation. \n",
      "The output is  ƒ(x) = max(0,x).  \n",
      "Why ReLU is important : ReLU’s purpos e is to introduce non -\n",
      "linearity in our ConvNet. Since, the real world data would want our \n",
      "ConvNet to learn would be non -negative linear values.  \n",
      " \n",
      "Figure 7 : ReLU operation  \n",
      "There are other non linear  functions such as tanh or sigmoid that \n",
      "can also be used instead of ReLU. Most of the data scientists use \n",
      "ReLU since performance wise ReLU is better than the other two.  \n",
      "Pooling Layer  \n",
      "Pooling layers section would reduce the number of parameters when \n",
      "the ima ges are too large. Spatial pooling also called subsampling or \n",
      "downsampling which reduces the dimensionality of each map but \n",
      "retains important information. Spatial pooling can be of different \n",
      "types:  \n",
      " Max Pooling  \n",
      " Average Pooling  \n",
      " Sum Pooling  \n",
      "Max pooling takes the largest element from the rectified feature \n",
      "map. Taking the largest element could also take the average pooling. \n",
      "Sum of all elements in the feature map call as sum pooling.  \n",
      " \n",
      "Figure 8 : Max Pooling  \n",
      "Fully Connected Layer  \n",
      "The layer we call as FC layer, we  flattened our matrix into vector and \n",
      "feed it into a fully connected layer like a neural network.  \n",
      " \n",
      "Figure 9 : After pooling layer, flattened as FC layer  \n",
      "In the above diagram, the feature map matrix will be converted as \n",
      "vector (x1, x2, x3, …). With the ful ly connected layers, we combined \n",
      "these features together to create a model. Finally, we have an \n",
      "activation function such as softmax or sigmoid to classify the \n",
      "outputs as cat, dog, car, truck etc.,  \n",
      " \n",
      "Figure 10 : Complete CNN architecture  \n",
      "Summary  \n",
      " Provide input image into convolution layer  \n",
      " Choose parameters, apply filters with strides, padding if \n",
      "requires. Perform convolution on the image and apply \n",
      "ReLU activation to the matrix.  \n",
      " Perform pooling to reduce dimensionality size  \n",
      " Add as many convolutional layers until satisfied  \n",
      " Flatten the output and feed into a fully connected layer (FC \n",
      "Layer)  \n",
      " Output the class using an activation function (Logistic \n",
      "Regression with cost functions) and classifies images.  \n",
      "In the next post, I would like to talk about some popular CNN  \n",
      "architectures such as AlexNet, VGGNet, GoogLeNet, and ResNet.  \n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        # Create a PDF reader object\n",
    "        pdf_reader = PyPDF2.PdfReader(file)\n",
    "\n",
    "        # Get the number of pages in the PDF\n",
    "        num_pages = len(pdf_reader.pages)\n",
    "\n",
    "        # Extract text from each page\n",
    "        text = ''\n",
    "        for page_num in range(num_pages):\n",
    "            # Get the page\n",
    "            page = pdf_reader.pages[page_num]\n",
    "\n",
    "            # Extract text from the page\n",
    "            text += page.extract_text()\n",
    "\n",
    "    return text\n",
    "\n",
    "# Example usage\n",
    "pdf_file_path = '/Users/mihiresh/Downloads/sumtest.pdf'  # Replace with your PDF file path\n",
    "extracted_text = extract_text_from_pdf(pdf_file_path)\n",
    "\n",
    "# Print the extracted text\n",
    "print(extracted_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN image classifications takes an input image, process it and classify it under certain categories (eg., Dog, Cat, Tiger, Lion). based on the image resolution, it will see h x w x d( h = Height, w = Width, d = Dimension. a seri es of convolution layers with filters (Kernels), Pooling, fully connected layers (FC) and apply Softmax function.\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "def summarize_text(text):\n",
    "    # Load pre-trained T5 model and tokenizer\n",
    "    model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
    "    tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "\n",
    "    # Tokenize input text\n",
    "    inputs = tokenizer.encode(\"summarize: \" + text, return_tensors=\"pt\", max_length=300000, truncation=True)\n",
    "\n",
    "    # Generate summary\n",
    "    summary_ids = model.generate(inputs, max_length=300000, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "# Example text to summarize\n",
    "input_text = extracted_text\n",
    "\n",
    "# Summarize the text\n",
    "summary = summarize_text(input_text)\n",
    "print(summary)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
